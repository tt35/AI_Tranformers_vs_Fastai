{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tt35/AI_Tranformers_vs_Fastai/blob/main/Final_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea44340c",
      "metadata": {
        "id": "ea44340c"
      },
      "source": [
        "#**Transformers vs. Fastai in image classification task - Part3**\n",
        "### Which one is better and more suitable for learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8f7251",
      "metadata": {
        "id": "0e8f7251"
      },
      "source": [
        "In this notebook, I would like to compare the accuracy and easiness of the Transformers model with the Fast.ai model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5aadfc",
      "metadata": {
        "id": "2c5aadfc"
      },
      "source": [
        "## Fast.ai model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436442e3",
      "metadata": {
        "id": "436442e3"
      },
      "source": [
        "The code below makes the Fast.ai image classfier by using the same images used for the Transformers model. Moreover, the model performance was evaluated with the same images as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7525e56",
      "metadata": {
        "id": "b7525e56"
      },
      "outputs": [],
      "source": [
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c98ce5",
      "metadata": {
        "id": "82c98ce5"
      },
      "outputs": [],
      "source": [
        "path = Path('/home/tt35/Desktop/pics_fastai_train/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53fca384",
      "metadata": {
        "id": "53fca384"
      },
      "outputs": [],
      "source": [
        "def is_CF(x):\n",
        "    return x[0] == \"C\"\n",
        "\n",
        "image_files = get_image_files(path).sorted()\n",
        "\n",
        "set_seed(1000)\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, image_files,\n",
        "    valid_pct=0.2, seed=42,\n",
        "    label_func=is_CF,\n",
        "    item_tfms=Resize(224),\n",
        "    bs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fadecc70",
      "metadata": {
        "id": "fadecc70",
        "outputId": "b64e9c91-1e4d-4288-e7c3-a7b4c6d46a3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.915965</td>\n",
              "      <td>0.319221</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.698574</td>\n",
              "      <td>0.188398</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.733255</td>\n",
              "      <td>0.064699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.563482</td>\n",
              "      <td>0.068833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn = cnn_learner(\n",
        "    dls=dls,\n",
        "    arch=resnet18,\n",
        "    metrics=accuracy,\n",
        ")\n",
        "learn.fine_tune(epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21574449",
      "metadata": {
        "id": "21574449"
      },
      "outputs": [],
      "source": [
        "test_path = Path('/home/tt35/Desktop/pics_fastai_test/')\n",
        "test_image_files = get_image_files(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f49eba",
      "metadata": {
        "id": "63f49eba"
      },
      "outputs": [],
      "source": [
        "test_dl = dls.test_dl(test_image_files, with_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea90e8ed",
      "metadata": {
        "id": "ea90e8ed",
        "outputId": "16fda96c-d674-43b5-a2d4-993d69c55ed7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn, dl=test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81572e6",
      "metadata": {
        "id": "c81572e6",
        "outputId": "864d8906-b977-4559-f3a7-2ca1ead55211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorBase(0.9412)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy(interp.preds, interp.targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1830c4d7",
      "metadata": {
        "id": "1830c4d7"
      },
      "source": [
        "## Results (accuracy on the test data, epoch = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab44a5e",
      "metadata": {
        "id": "5ab44a5e"
      },
      "source": [
        "**Fast.ai Model**\n",
        "```\n",
        "seed = 1: \n",
        "  accuracy = 0.8235\n",
        "  \n",
        "seed = 10:\n",
        "  accuracy = 0.7353\n",
        "  \n",
        "seed = 100:\n",
        "  accuracy = 0.7647\n",
        "  \n",
        "seed = 1000:\n",
        "  accuracy = 0.9412\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5366639a",
      "metadata": {
        "id": "5366639a"
      },
      "source": [
        "**Transformers Model**\n",
        "```\n",
        "seed = 1: \n",
        "  eval_accuracy = 1.0\n",
        " \n",
        "seed = 10:\n",
        "  eval_accuracy = 1.0\n",
        "  \n",
        "seed = 100:\n",
        "  eval_accuracy = 1.0\n",
        "  \n",
        "seed = 1000:\n",
        "  eval_accuracy = 0.8824\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44ca09ce",
      "metadata": {
        "id": "44ca09ce"
      },
      "source": [
        "## Reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d9ed663",
      "metadata": {
        "id": "0d9ed663"
      },
      "source": [
        "The range of accuracy for Transformers model is 0.88 to 1.0, and it is 0.74 to 0.94. As the results show, the accuracy of Transformers model is much better than the one of Fast.ai model. In terms of usability, I would say Fast.ai model was a lot easier as it has some very useful API such as ImageDataLoaders.from_path_func. Unlike Fast.ai, Transformers do not have straightforward APIs, which requires the users to write a lot of code on their own."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations and Future Directions\t"
      ],
      "metadata": {
        "id": "q-bFHN6UV-KN"
      },
      "id": "q-bFHN6UV-KN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I said above, the limitations come from the variety of pictures. For example, some images include cars and gloomy sky. Since I am not exactly sure how much these factors influence the model performance, the future direction is to create attention heat map, so that we can see exactly what parts the model pays attention. "
      ],
      "metadata": {
        "id": "Yn3k5NPTWKw_"
      },
      "id": "Yn3k5NPTWKw_"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Final_Project_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}